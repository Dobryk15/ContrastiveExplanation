{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "seed = RandomState(1994)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, model_selection, ensemble, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "Contrastive explanation for an instance of the [Iris](https://archive.ics.uci.edu/ml/datasets/iris) data set\n",
    "\n",
    "---\n",
    "\n",
    "**1. Train a (black-box) model on the Iris data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier performance (F1): 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_iris()\n",
    "train, test, y_train, y_test = model_selection.train_test_split(data.data, \n",
    "                                                                data.target, \n",
    "                                                                train_size=0.80, \n",
    "                                                                random_state=seed)\n",
    "model = ensemble.RandomForestClassifier(random_state=seed)\n",
    "model.fit(train, y_train)\n",
    "\n",
    "print('Classifier performance (F1):', metrics.f1_score(y_test, model.predict(test), average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Perform contrastive explanation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The model predicted 'setosa' instead of 'versicolor' because 'petal length (cm) <= 2.529 and sepal width (cm) <= 3.561'\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import\n",
    "import contrastive_explanation as ce\n",
    "\n",
    "# Select a sample to explain ('questioned data point') why it predicted the fact instead of the foil \n",
    "sample = test[0] \n",
    "\n",
    "# Create a domain mapper (map the explanation to meaningful labels for explanation)\n",
    "dm = ce.domain_mappers.DomainMapperTabular(train, \n",
    "                                           feature_names=data.feature_names,\n",
    "                                           contrast_names=data.target_names)\n",
    "\n",
    "# Create the contrastive explanation object (default is a Foil Tree explanator)\n",
    "exp = ce.ContrastiveExplanation(dm)\n",
    "\n",
    "# Explain the instance (sample) for the given model\n",
    "exp.explain_instance_domain(model.predict_proba, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "Explain an instance of the [Diabetes](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes) data set\n",
    "\n",
    "**1. Train a (black-box) model on the Diabetes data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressor performance (R-squared): 0.5086602809470543\n"
     ]
    }
   ],
   "source": [
    "data_reg = datasets.load_diabetes()\n",
    "\n",
    "train, test, y_train, y_test = model_selection.train_test_split(data_reg.data, \n",
    "                                                                data_reg.target, \n",
    "                                                                train_size=0.80, \n",
    "                                                                random_state=seed)\n",
    "m_cv = ensemble.RandomForestRegressor(random_state=seed)\n",
    "model_reg = model_selection.GridSearchCV(m_cv, param_grid={'n_estimators': [50, 100, 500]})\n",
    "\n",
    "model_reg.fit(train, y_train)\n",
    "\n",
    "print('Regressor performance (R-squared):', metrics.r2_score(y_test, model_reg.predict(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Perform contrastive explanation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F] Picked foil \"more than 92.414\" using foil selection strategy \"greater\"\n",
      "[D] Obtaining neighborhood data\n",
      "[E] Explaining with a decision tree...\n",
      "[E] Fidelity of tree on neighborhood data = 1.0\n",
      "[E] Found 9 contrastive decision regions, starting from node 2\n",
      "[E] Found shortest path [19, 18, 20, 21] using strategy \"informativeness\"\n",
      "[C] Decision obtained: [(6, 0.10606995224952698, 0.100183028707369, True, False), (0, -0.014294859021902084, -0.0164121703318693, False, False)]\n",
      "[C] Combining full rules [Literal(feature=6, operator=<Operator.SEQ: '<='>, value=0.10606995224952698, categorical=False)]...\n",
      "[C] Decision obtained: [(2, 0.006363794207572937, -0.0353068801305926, False, False), (8, -0.002834510989487171, -0.0702093127286876, False, False), (6, 0.020282596349716187, 0.100183028707369, False, True), (3, 0.05408908426761627, -0.0263278347173518, True, False), (7, 0.024366647005081177, -0.0394933828740919, False, False), (4, -0.057564325630664825, 0.0328298616348169, False, True), (4, 0.023079968988895416, 0.0328298616348169, True, True), (0, -0.029869213700294495, -0.0164121703318693, True, True), (7, 0.016373664140701294, -0.0394933828740919, True, False), (5, -0.0018317645881325006, 0.0171618818193638, False, True), (4, 0.11302484571933746, 0.0328298616348169, True, False), (3, -0.01771952398121357, -0.0263278347173518, False, False), (9, 0.0032340213656425476, -0.0797777288823259, False, False), (-2, -2.0, -0.0702093127286876, False, True)]\n",
      "[C] Combining full rules [Literal(feature=2, operator=<Operator.SEQ: '<='>, value=0.006363794207572937, categorical=False), Literal(feature=8, operator=<Operator.SEQ: '<='>, value=-0.002834510989487171, categorical=False), Literal(feature=6, operator=<Operator.SEQ: '<='>, value=0.020282596349716187, categorical=False), Literal(feature=3, operator=<Operator.GT: '>'>, value=0.05408908426761627, categorical=False), Literal(feature=7, operator=<Operator.SEQ: '<='>, value=0.024366647005081177, categorical=False), Literal(feature=4, operator=<Operator.SEQ: '<='>, value=-0.057564325630664825, categorical=False), Literal(feature=4, operator=<Operator.GT: '>'>, value=0.023079968988895416, categorical=False), Literal(feature=0, operator=<Operator.GT: '>'>, value=-0.029869213700294495, categorical=False), Literal(feature=7, operator=<Operator.GT: '>'>, value=0.016373664140701294, categorical=False), Literal(feature=5, operator=<Operator.SEQ: '<='>, value=-0.0018317645881325006, categorical=False), Literal(feature=4, operator=<Operator.GT: '>'>, value=0.11302484571933746, categorical=False), Literal(feature=3, operator=<Operator.SEQ: '<='>, value=-0.01771952398121357, categorical=False), Literal(feature=9, operator=<Operator.SEQ: '<='>, value=0.0032340213656425476, categorical=False), Literal(feature=-2, operator=<Operator.SEQ: '<='>, value=-2.0, categorical=False)]...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"The model predicted '92.414' instead of 'more than 92.414' because 's3 <= 0.106'\",\n",
       " \"The model predicted '92.414' because 'bmi <= 0.006 and s5 <= -0.003 and s3 <= 0.02 and bp > 0.054 and s4 <= 0.024 and s1 <= -0.058 and s1 > 0.023 and age > -0.03 and s4 > 0.016 and s2 <= -0.002 and s1 > 0.113 and bp <= -0.018'\")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import contrastive_explanation as ce\n",
    "\n",
    "# Select a sample to explain\n",
    "sample = test[1]\n",
    "\n",
    "# Create a domain mapper (still tabular data, but for regression we do not have named labels for the outcome),\n",
    "# ensure that 'sex' is a categorical feature\n",
    "dm = ce.domain_mappers.DomainMapperTabular(train, \n",
    "                                           feature_names=data_reg.feature_names,\n",
    "                                           categorical_features=[1])\n",
    "\n",
    "# Create the CE objects, ensure that 'regression' is set to True\n",
    "# again, we use the Foil Tree explanator, but now we print out intermediary outcomes and steps (verbose)\n",
    "exp = ce.ContrastiveExplanation(dm,\n",
    "                                regression=True,\n",
    "                                explanator=ce.explanators.TreeExplanator(verbose=True),\n",
    "                                verbose=True)\n",
    "\n",
    "# Explain using the model, also include a 'factual' (non-contrastive 'why fact?') explanation\n",
    "exp.explain_instance_domain(model_reg.predict, sample, include_factual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
