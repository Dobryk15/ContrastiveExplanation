{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ContrastiveExplanation\n",
    "This file contains a Notebook for example usage of the `ContrastiveExplanation` Python script, so that you can familiarize yourself with the usage flow and showcasing the package functionalities. It contains two examples, one for explaining a classification problem and one for explaining a regression analysis problem.\n",
    "\n",
    "First, let us set a seed for reproducibility, and import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "SEED = RandomState(1994)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, model_selection, ensemble, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For printing out the features and their corresponding values of an instance we define a function `print_sample()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "def print_sample(feature_names, sample):\n",
    "    print('\\n'.join(f'{name}: {value}' for name, value in zip(feature_names, sample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "First, for classification we use the [Iris](https://archive.ics.uci.edu/ml/datasets/iris) data set (as also used in the example of `README.md`. We first load the data set (and print its characteristics), then train an ML model on the data, and finally explain an instance predicted using the model.\n",
    "\n",
    "---\n",
    "**0. Data set characteristics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_iris()\n",
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Train a (black-box) model on the Iris data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier performance (F1): 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Split data in a train/test set and in predictor (x) and target (y) variables\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(data.data, \n",
    "                                                                    data.target, \n",
    "                                                                    train_size=0.80, \n",
    "                                                                    random_state=SEED)\n",
    "\n",
    "# Train a RandomForestClassifier\n",
    "model = ensemble.RandomForestClassifier(random_state=SEED, n_estimators=100)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Print out the classifier performance (F1-score)\n",
    "print('Classifier performance (F1):', metrics.f1_score(y_test, model.predict(x_test), average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2a. Perform contrastive explanation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm): 5.1\n",
      "sepal width (cm): 3.8\n",
      "petal length (cm): 1.5\n",
      "petal width (cm): 0.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The model predicted 'setosa' instead of 'versicolor' because 'petal length (cm) <= 2.528 and petal width (cm) <= 1.704 and sepal length (cm) <= 5.159'\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import\n",
    "import contrastive_explanation as ce\n",
    "\n",
    "# Select a sample to explain ('questioned data point') why it predicted the fact instead of the foil \n",
    "sample = x_test[1]\n",
    "print_sample(data.feature_names, sample)\n",
    "\n",
    "# Create a domain mapper (map the explanation to meaningful labels for explanation)\n",
    "dm = ce.domain_mappers.DomainMapperTabular(x_train,\n",
    "                                           feature_names=data.feature_names,\n",
    "                                           contrast_names=data.target_names)\n",
    "\n",
    "# Create the contrastive explanation object (default is a Foil Tree explanator)\n",
    "exp = ce.ContrastiveExplanation(dm)\n",
    "\n",
    "# Explain the instance (sample) for the given model\n",
    "exp.explain_instance_domain(model.predict_proba, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2b. Perform contrastive explanation on manually selected foil**\n",
    "\n",
    "Instead, we can also manually provide a foil to explain (e.g. class 'virginica'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The model predicted 'setosa' instead of 'virginica' because 'petal length (cm) <= 5.133 and sepal length (cm) <= 6.059'\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.explain_instance_domain(model.predict_proba, sample, foil='virginica')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "Here, we explain an instance of the [Diabetes](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes) data set using the same steps as the classification problem.\n",
    "\n",
    "---\n",
    "**0. Data set characteristics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - Age\n",
      "      - Sex\n",
      "      - Body mass index\n",
      "      - Average blood pressure\n",
      "      - S1\n",
      "      - S2\n",
      "      - S3\n",
      "      - S4\n",
      "      - S5\n",
      "      - S6\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "r_data = datasets.load_diabetes()\n",
    "print(r_data['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Train a (black-box) model on the Diabetes data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressor performance (R-squared): 0.4054625517721193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Split data in a train/test set and in predictor (x) and target (y) variables\n",
    "rx_train, rx_test, ry_train, ry_test = model_selection.train_test_split(r_data.data, \n",
    "                                                                        r_data.target, \n",
    "                                                                        train_size=0.80, \n",
    "                                                                        random_state=SEED)\n",
    "\n",
    "# Train a RandomForestRegressor with hyperparameter tuning (selecting the best n_estimators)\n",
    "m_cv = ensemble.RandomForestRegressor(random_state=SEED)\n",
    "r_model = model_selection.GridSearchCV(m_cv, cv=5, param_grid={'n_estimators': [50, 100, 500]})\n",
    "r_model.fit(rx_train, ry_train)\n",
    "\n",
    "# Print out the regressor performance\n",
    "print('Regressor performance (R-squared):', metrics.r2_score(ry_test, r_model.predict(rx_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Perform contrastive explanation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 0.0380759064334241\n",
      "sex: 0.0506801187398187\n",
      "bmi: -0.0299178197611881\n",
      "bp: -0.0745280244296595\n",
      "s1: -0.0125765826858204\n",
      "s2: -0.0125872220506418\n",
      "s3: 0.00446044580110504\n",
      "s4: -0.00259226199818282\n",
      "s5: 0.00371173823343597\n",
      "s6: -0.0300724459043093\n",
      "\n",
      "\n",
      "[E] Explaining with a decision tree...\n",
      "[E] Fidelity of tree on neighborhood data = 1.0\n",
      "[E] Found 15 contrastive decision regions, starting from node 2\n",
      "[E] Found shortest path [42, 41, 43] using strategy \"informativeness\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"The model predicted '128.38' instead of 'more than 128.38' because 's6 <= 0.069'\",\n",
       " \"The model predicted '128.38' because 'bmi <= 0.01 and s5 <= -0.026 and age > 0.021 and bmi > 0.001 and s4 <= -0.046 and s3 > -0.015 and sex > 0.085'\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import\n",
    "import contrastive_explanation as ce\n",
    "\n",
    "# Select a sample to explain\n",
    "r_sample = rx_test[1]\n",
    "print_sample(r_data.feature_names, r_sample)\n",
    "print('\\n')\n",
    "\n",
    "# Create a domain mapper (still tabular data, but for regression we do not have named labels for the outcome)\n",
    "r_dm = ce.domain_mappers.DomainMapperTabular(rx_train, \n",
    "                                             feature_names=r_data.feature_names)\n",
    "\n",
    "# Create the CE objects, ensure that 'regression' is set to True\n",
    "# again, we use the Foil Tree explanator, but now we print out intermediary outcomes and steps (verbose)\n",
    "r_exp = ce.ContrastiveExplanation(r_dm,\n",
    "                                  regression=True,\n",
    "                                  explanator=ce.explanators.TreeExplanator(verbose=True),\n",
    "                                  verbose=False)\n",
    "\n",
    "# Explain using the model, also include a 'factual' (non-contrastive 'why fact?') explanation\n",
    "r_exp.explain_instance_domain(r_model.predict, r_sample, include_factual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
