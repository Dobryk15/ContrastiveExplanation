{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ContrastiveExplanation\n",
    "This file contains a Notebook for example usage of the `ContrastiveExplanation` Python script, so that you can familiarize yourself with the usage flow and showcasing the package functionalities. It contains three examples, two for explaining classification problems and one for explaining a regression analysis problem.\n",
    "\n",
    "###### Contents\n",
    "1. [Classification (continuous features)](#classification-1)\n",
    "2. [Classification (Pandas DataFrame, categorical features) ](#classification-2)\n",
    "3. [Regression](#regression-1)\n",
    "\n",
    "---\n",
    "\n",
    "Before we proceed, let us set a seed for reproducibility, and import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import urllib.request\n",
    "import pprint\n",
    "\n",
    "from sklearn import datasets, model_selection, ensemble, metrics, pipeline, preprocessing\n",
    "\n",
    "SEED = np.random.RandomState(1994)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For printing out the features and their corresponding values of an instance we define a function `print_sample()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample(feature_names, sample):\n",
    "    print('\\n'.join(f'{name}: {value}' for name, value in zip(feature_names, sample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Classification (continuous features) <a name=\"classification-1\"></a>\n",
    "First, for classification we use the [Iris](https://archive.ics.uci.edu/ml/datasets/iris) data set (as also used in the example of `README.md`. We first load the data set (and print its characteristics), then train an ML model on the data, and finally explain an instance predicted using the model.\n",
    "\n",
    "#### 1.1 Data set characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_iris()\n",
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Train a (black-box) model on the Iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier performance (F1): 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Split data in a train/test set and in predictor (x) and target (y) variables\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(data.data, \n",
    "                                                                    data.target, \n",
    "                                                                    train_size=0.80, \n",
    "                                                                    random_state=SEED)\n",
    "\n",
    "# Train a RandomForestClassifier\n",
    "model = ensemble.RandomForestClassifier(random_state=SEED, n_estimators=100)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Print out the classifier performance (F1-score)\n",
    "print('Classifier performance (F1):', metrics.f1_score(y_test, model.predict(x_test), average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3a Perform contrastive explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm): 5.1\n",
      "sepal width (cm): 3.8\n",
      "petal length (cm): 1.5\n",
      "petal width (cm): 0.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The model predicted 'setosa' instead of 'versicolor' because 'petal length (cm) <= 2.528 and petal width (cm) <= 1.704 and sepal length (cm) <= 5.159'\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import\n",
    "import contrastive_explanation as ce\n",
    "\n",
    "# Select a sample to explain ('questioned data point') why it predicted the fact instead of the foil \n",
    "sample = x_test[1]\n",
    "print_sample(data.feature_names, sample)\n",
    "\n",
    "# Create a domain mapper (map the explanation to meaningful labels for explanation)\n",
    "dm = ce.domain_mappers.DomainMapperTabular(x_train,\n",
    "                                           feature_names=data.feature_names,\n",
    "                                           contrast_names=data.target_names)\n",
    "\n",
    "# Create the contrastive explanation object (default is a Foil Tree explanator)\n",
    "exp = ce.ContrastiveExplanation(dm)\n",
    "\n",
    "# Explain the instance (sample) for the given model\n",
    "exp.explain_instance_domain(model.predict_proba, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3b Perform contrastive explanation on manually selected foil\n",
    "\n",
    "Instead, we can also manually provide a foil to explain (e.g. class 'virginica'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The model predicted 'setosa' instead of 'virginica' because 'petal length (cm) <= 5.133 and sepal length (cm) <= 6.059'\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.explain_instance_domain(model.predict_proba, sample, foil='virginica')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification (Pandas DataFrame, categorical features) <a name=\"classification-2\"></a>\n",
    "We use the [Adult Census Income](https://archive.ics.uci.edu/ml/datasets/Adult) data set from the UCI Machine Learning repository as an additional classification example, where we showcase the usage of multi-valued categorical features and Pandas DataFrames as input.\n",
    "\n",
    "---\n",
    "#### 2.1 Data set characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import contrastive_explanation as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  education      marital-status         occupation  \\\n",
       "0   39         State-gov  Bachelors       Never-married       Adm-clerical   \n",
       "1   50  Self-emp-not-inc  Bachelors  Married-civ-spouse    Exec-managerial   \n",
       "2   38           Private    HS-grad            Divorced  Handlers-cleaners   \n",
       "3   53           Private       11th  Married-civ-spouse  Handlers-cleaners   \n",
       "4   28           Private  Bachelors  Married-civ-spouse     Prof-specialty   \n",
       "\n",
       "    relationship   race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0  Not-in-family  White    Male          2174             0              40   \n",
       "1        Husband  White    Male             0             0              13   \n",
       "2  Not-in-family  White    Male             0             0              40   \n",
       "3        Husband  Black    Male             0             0              40   \n",
       "4           Wife  Black  Female             0             0              40   \n",
       "\n",
       "  native-country  class  \n",
       "0  United-States  <=50K  \n",
       "1  United-States  <=50K  \n",
       "2  United-States  <=50K  \n",
       "3  United-States  <=50K  \n",
       "4           Cuba  <=50K  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the adult data set (https://archive.ics.uci.edu/ml/datasets/Adult)\n",
    "c_file = ce.utils.download_data('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data')\n",
    "c_df = pd.read_csv(c_file, header=None, skipinitialspace=True)\n",
    "c_df = c_df.drop([2, 4], axis=1)\n",
    "\n",
    "# Give descriptive names to features\n",
    "c_features    = ['age', 'workclass', 'education', 'marital-status',\n",
    "                 'occupation', 'relationship', 'race', 'sex',\n",
    "                 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "                 'native-country']\n",
    "c_categorical = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                 'relationship', 'race', 'sex', 'native-country']\n",
    "c_df.columns  = c_features + ['class']\n",
    "c_contrasts   = c_df['class'].unique()\n",
    "\n",
    "# Split into x and y (class feature is last feature)\n",
    "cx, cy = c_df.iloc[:, :-1], c_df.iloc[:, -1]\n",
    "c_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Train a (black-box) model on the Adult data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier performance (F1): 0.8653015631373624\n"
     ]
    }
   ],
   "source": [
    "# Split data in a train/test set and in predictor (x) and target (y) variables\n",
    "cx_train, cx_test, cy_train, cy_test = model_selection.train_test_split(cx, \n",
    "                                                                        cy, \n",
    "                                                                        train_size=0.80, \n",
    "                                                                        random_state=SEED)\n",
    "\n",
    "# Train a AdaBoostClassifier\n",
    "c_model = pipeline.Pipeline([('label_encoder', ce.CustomLabelEncoder(c_categorical).fit(cx)),\n",
    "                             ('classifier', ensemble.AdaBoostClassifier(random_state=SEED, n_estimators=100))])\n",
    "c_model.fit(cx_train, cy_train)\n",
    "\n",
    "# Print out the classifier performance (F1-score)\n",
    "print('Classifier performance (F1):', metrics.f1_score(cy_test, c_model.predict(cx_test), average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Perform contrastive explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                           22\n",
      "workclass                Private\n",
      "education           Some-college\n",
      "marital-status     Never-married\n",
      "occupation                 Sales\n",
      "relationship      Other-relative\n",
      "race                       White\n",
      "sex                         Male\n",
      "capital-gain                   0\n",
      "capital-loss                   0\n",
      "hours-per-week                38\n",
      "native-country     United-States\n",
      "Name: 18253, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The model predicted '<=50K' instead of '>50K' because 'marital-status = Widowed and age <= 24.457'\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a sample to explain ('questioned data point') why it predicted the fact instead of the foil \n",
    "sample = cx_test.iloc[1]\n",
    "print(sample)\n",
    "\n",
    "# Create a domain mapper for the Pandas DataFrame (it will automatically infer feature names)\n",
    "c_dm = ce.domain_mappers.DomainMapperPandas(cx_train,\n",
    "                                            contrast_names=c_contrasts)\n",
    "\n",
    "# Create the contrastive explanation object (default is a Foil Tree explanator)\n",
    "c_exp = ce.ContrastiveExplanation(c_dm)\n",
    "\n",
    "# Explain the instance (sample) for the given model\n",
    "c_exp.explain_instance_domain(c_model.predict_proba, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Regression <a name=\"regression-1\"></a>\n",
    "Here, we explain an instance of the [Diabetes](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes) data set using the same steps as the classification problems. Instead of just the counterfactual explanation (difference between fact and foil), this example also includes the factual explanation (difference of fact versus all foils).\n",
    "\n",
    "#### 3.1 Data set characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - Age\n",
      "      - Sex\n",
      "      - Body mass index\n",
      "      - Average blood pressure\n",
      "      - S1\n",
      "      - S2\n",
      "      - S3\n",
      "      - S4\n",
      "      - S5\n",
      "      - S6\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "r_data = datasets.load_diabetes()\n",
    "print(r_data['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Train a (black-box) model on the Diabetes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressor performance (R-squared): 0.40216144211319016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Split data in a train/test set and in predictor (x) and target (y) variables\n",
    "rx_train, rx_test, ry_train, ry_test = model_selection.train_test_split(r_data.data, \n",
    "                                                                        r_data.target, \n",
    "                                                                        train_size=0.80, \n",
    "                                                                        random_state=SEED)\n",
    "\n",
    "# Train a RandomForestRegressor with hyperparameter tuning (selecting the best n_estimators)\n",
    "m_cv = ensemble.RandomForestRegressor(random_state=SEED)\n",
    "r_model = model_selection.GridSearchCV(m_cv, cv=5, param_grid={'n_estimators': [50, 100, 500]})\n",
    "r_model.fit(rx_train, ry_train)\n",
    "\n",
    "# Print out the regressor performance\n",
    "print('Regressor performance (R-squared):', metrics.r2_score(ry_test, r_model.predict(rx_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Perform contrastive explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: -0.0309423241359475\n",
      "sex: -0.044641636506989\n",
      "bmi: 0.00564997867688165\n",
      "bp: -0.00911348124867051\n",
      "s1: 0.0190703330528056\n",
      "s2: 0.00682798258030921\n",
      "s3: 0.0744115640787594\n",
      "s4: -0.0394933828740919\n",
      "s5: -0.0411803851880079\n",
      "s6: -0.0424987666488135\n",
      "\n",
      "\n",
      "[E] Explaining with a decision tree...\n",
      "[E] Fidelity of tree on neighborhood data = 1.0\n",
      "[E] Found 10 contrastive decision regions, starting from node 2\n",
      "[E] Found shortest path [25, 23, 24] using strategy \"informativeness\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"The model predicted '113.68' instead of 'more than 113.68' because 's2 > -0.0'\",\n",
       " \"The model predicted '113.68' because 's5 <= -0.012 and bmi <= 0.007 and s5 <= -0.045 and age > 0.024 and sex <= -0.044 and age <= -0.029 and s4 <= 0.003'\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import\n",
    "import contrastive_explanation as ce\n",
    "\n",
    "# Select a sample to explain\n",
    "r_sample = rx_test[1]\n",
    "print_sample(r_data.feature_names, r_sample)\n",
    "print('\\n')\n",
    "\n",
    "# Create a domain mapper (still tabular data, but for regression we do not have named labels for the outcome)\n",
    "r_dm = ce.domain_mappers.DomainMapperTabular(rx_train, \n",
    "                                             feature_names=r_data.feature_names)\n",
    "\n",
    "# Create the CE objects, ensure that 'regression' is set to True\n",
    "# again, we use the Foil Tree explanator, but now we print out intermediary outcomes and steps (verbose)\n",
    "r_exp = ce.ContrastiveExplanation(r_dm,\n",
    "                                  regression=True,\n",
    "                                  explanator=ce.explanators.TreeExplanator(verbose=True),\n",
    "                                  verbose=False)\n",
    "\n",
    "# Explain using the model, also include a 'factual' (non-contrastive 'why fact?') explanation\n",
    "r_exp.explain_instance_domain(r_model.predict, r_sample, include_factual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
