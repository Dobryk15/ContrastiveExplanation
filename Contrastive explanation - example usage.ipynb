{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "seed = RandomState(1994)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, model_selection, ensemble, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "Contrastive explanation for an instance of the [Iris](https://archive.ics.uci.edu/ml/datasets/iris) data set\n",
    "\n",
    "---\n",
    "\n",
    "**1. Train a (black-box) model on the Iris data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier performance (F1): 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_iris()\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(data.data, \n",
    "                                                                data.target, \n",
    "                                                                train_size=0.80, \n",
    "                                                                random_state=seed)\n",
    "model = ensemble.RandomForestClassifier(random_state=seed)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print('Classifier performance (F1):', metrics.f1_score(y_test, model.predict(x_test), average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(data.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Perform contrastive explanation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The model predicted 'setosa' instead of 'versicolor' because 'petal width (cm) <= 0.701 and petal length (cm) <= 2.159 and petal width (cm) <= 0.798 and sepal length (cm) <= 5.993'\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import\n",
    "import contrastive_explanation as ce\n",
    "\n",
    "# Select a sample to explain ('questioned data point') why it predicted the fact instead of the foil \n",
    "sample = x_test[4] \n",
    "\n",
    "# Create a domain mapper (map the explanation to meaningful labels for explanation)\n",
    "dm = ce.domain_mappers.DomainMapperTabular(x_train,\n",
    "                                           feature_names=data.feature_names,\n",
    "                                           contrast_names=data.target_names)\n",
    "\n",
    "# Create the contrastive explanation object (default is a Foil Tree explanator)\n",
    "exp = ce.ContrastiveExplanation(dm)\n",
    "\n",
    "# Explain the instance (sample) for the given model\n",
    "exp.explain_instance_domain(model.predict_proba, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "Explain an instance of the [Diabetes](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes) data set\n",
    "\n",
    "**1. Train a (black-box) model on the Diabetes data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressor performance (R-squared): 0.873933146710173\n"
     ]
    }
   ],
   "source": [
    "data_reg = datasets.load_diabetes()\n",
    "\n",
    "rx_train, rx_test, ry_train, ry_test = model_selection.train_test_split(data_reg.data, \n",
    "                                                                        data_reg.target, \n",
    "                                                                        train_size=0.80, \n",
    "                                                                        random_state=seed)\n",
    "m_cv = ensemble.RandomForestRegressor(random_state=seed)\n",
    "r_model = model_selection.GridSearchCV(m_cv, param_grid={'n_estimators': [50, 100, 500]})\n",
    "\n",
    "r_model.fit(rx_train, ry_train)\n",
    "\n",
    "print('Regressor performance (R-squared):', metrics.r2_score(ry_test, model_reg.predict(rx_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - Age\n",
      "      - Sex\n",
      "      - Body mass index\n",
      "      - Average blood pressure\n",
      "      - S1\n",
      "      - S2\n",
      "      - S3\n",
      "      - S4\n",
      "      - S5\n",
      "      - S6\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "print(data_reg['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Perform contrastive explanation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F] Picked foil \"more than 134.898\" using foil selection strategy \"greater\"\n",
      "[D] Obtaining neighborhood data\n",
      "[E] Explaining with a decision tree...\n",
      "[E] Fidelity of tree on neighborhood data = 1.0\n",
      "[E] Found 5 contrastive decision regions, starting from node 2\n",
      "[E] Found shortest path [13, 12, 14, 16] using strategy \"informativeness\"\n",
      "[C] Decision obtained: [(3, 0.08280231058597565, 0.0666296740135272, True, False), (0, 0.04994678683578968, 0.0380759064334241, True, False)]\n",
      "[C] Combining full rules [Literal(feature=3, operator=<Operator.SEQ: '<='>, value=0.08280231058597565, categorical=False), Literal(feature=0, operator=<Operator.SEQ: '<='>, value=0.04994678683578968, categorical=False)]...\n",
      "[C] Decision obtained: [(2, 0.005121644586324692, -0.0180618869484982, False, False), (8, -0.004276006133295596, -0.0119006848015081, False, False), (8, -0.030646467581391335, -0.0119006848015081, False, True), (6, -0.028987007215619087, -0.0765355858888105, True, False), (8, -0.01580944936722517, -0.0119006848015081, False, True), (0, 0.042625442147254944, 0.0380759064334241, True, False), (2, -0.02221822552382946, -0.0180618869484982, False, True), (0, -0.0002188514918088913, 0.0380759064334241, True, True), (-2, -2.0, -0.0119006848015081, False, True)]\n",
      "[C] Combining full rules [Literal(feature=2, operator=<Operator.SEQ: '<='>, value=0.005121644586324692, categorical=False), Literal(feature=8, operator=<Operator.SEQ: '<='>, value=-0.004276006133295596, categorical=False), Literal(feature=8, operator=<Operator.SEQ: '<='>, value=-0.030646467581391335, categorical=False), Literal(feature=6, operator=<Operator.GT: '>'>, value=-0.028987007215619087, categorical=False), Literal(feature=8, operator=<Operator.SEQ: '<='>, value=-0.01580944936722517, categorical=False), Literal(feature=0, operator=<Operator.GT: '>'>, value=0.042625442147254944, categorical=False), Literal(feature=2, operator=<Operator.SEQ: '<='>, value=-0.02221822552382946, categorical=False), Literal(feature=0, operator=<Operator.GT: '>'>, value=-0.0002188514918088913, categorical=False), Literal(feature=-2, operator=<Operator.SEQ: '<='>, value=-2.0, categorical=False)]...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"The model predicted '134.898' instead of 'more than 134.898' because 'bp <= 0.083 and age <= 0.05'\",\n",
       " \"The model predicted '134.898' because 'bmi <= 0.005 and s5 <= -0.031 and s3 > -0.029 and s5 <= -0.016 and age > 0.043 and bmi <= -0.022'\")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import contrastive_explanation as ce\n",
    "\n",
    "# Select a sample to explain\n",
    "r_sample = test[1]\n",
    "\n",
    "# Create a domain mapper (still tabular data, but for regression we do not have named labels for the outcome),\n",
    "# ensure that 'sex' is a categorical feature\n",
    "r_dm = ce.domain_mappers.DomainMapperTabular(rx_train, \n",
    "                                             feature_names=data_reg.feature_names,\n",
    "                                             categorical_features=[1])\n",
    "\n",
    "# Create the CE objects, ensure that 'regression' is set to True\n",
    "# again, we use the Foil Tree explanator, but now we print out intermediary outcomes and steps (verbose)\n",
    "r_exp = ce.ContrastiveExplanation(r_dm,\n",
    "                                  regression=True,\n",
    "                                  explanator=ce.explanators.TreeExplanator(verbose=True),\n",
    "                                  verbose=True)\n",
    "\n",
    "# Explain using the model, also include a 'factual' (non-contrastive 'why fact?') explanation\n",
    "r_exp.explain_instance_domain(r_model.predict, r_sample, include_factual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
